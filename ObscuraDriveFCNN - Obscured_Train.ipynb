{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65721599-6e5e-48c9-a4c9-0d9f68a22512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the working directory\n",
    "working_directory = \"/Users/saeah/.cache/kagglehub/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign/versions/1\"\n",
    "os.chdir(working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e13d32-f61a-4206-b069-e0fbefa6d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/saeah/.cache/kagglehub/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign/versions/1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980ccf21-0df7-4572-a27c-42258cb0c3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    print(f\"MPS is available. Using GPU.\")\n",
    "else:\n",
    "    print(\"MPS is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe4518-b44e-42f2-97cd-d42d01ce3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Ensure reproducibility\n",
    "RANDOM_SEED = 1\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 43  # Number of traffic sign classes\n",
    "epochs = 40\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "### DATA AUGMENTATION\n",
    "# Transformations for training (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),  # Small rotations and translations\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color variations\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=0),  # Simulating occlusions\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Transformations for testing (NO augmentations, only normalization)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Custom Dataset class for GTSRB\n",
    "class GTSRBDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Reorder columns: Move 'ClassId' and 'Path' to the first two positions\n",
    "        columns = self.data.columns.tolist()\n",
    "        new_order = ['ClassId', 'Path'] + [col for col in columns if col not in ['ClassId', 'Path']]\n",
    "        self.data = self.data[new_order]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 1]  # Use path directly from CSV\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.data.iloc[idx, 0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = GTSRBDataset(csv_file=\"Obscured_Train.csv\", transform=train_transform)\n",
    "test_dataset = GTSRBDataset(csv_file=\"Obscured_Test.csv\", transform=test_transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BALANCE THE DATASET\n",
    "\n",
    "from collections import Counter\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Get class distribution\n",
    "class_counts = train_dataset.data['ClassId'].value_counts().to_dict()\n",
    "max_samples = max(class_counts.values())  # Maximum images in a single class\n",
    "\n",
    "# Create a new balanced dataset by oversampling underrepresented classes\n",
    "balanced_data = []\n",
    "\n",
    "for class_id, count in class_counts.items():\n",
    "    class_samples = train_dataset.data[train_dataset.data['ClassId'] == class_id]\n",
    "    \n",
    "    # If the class has fewer samples, randomly duplicate its entries\n",
    "    if count < max_samples:\n",
    "        extra_samples = class_samples.sample(n=max_samples - count, replace=True, random_state=RANDOM_SEED)\n",
    "        class_samples = pd.concat([class_samples, extra_samples])\n",
    "    \n",
    "    balanced_data.append(class_samples)\n",
    "\n",
    "# Concatenate all balanced data\n",
    "balanced_df = pd.concat(balanced_data).reset_index(drop=True)\n",
    "\n",
    "# Update the dataset\n",
    "train_dataset.data = balanced_df\n",
    "\n",
    "# Create new DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Fully Connected Neural Network Model with 2 layers\n",
    "class TwoFCLayers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoFCLayers, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 1024)  # Flatten 32x32x3 image to 1024 hidden units\n",
    "        # self.dropout1 = nn.Dropout(0.3)  # Dropout with 50% probability\n",
    "        self.fc2 = nn.Linear(1024, 1024)     # Hidden layer\n",
    "        # self.dropout2 = nn.Dropout(0.3)  # Dropout with 50% probability\n",
    "        self.fc3 = nn.Linear(1024, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32*3)  # Flatten the input (batch_size, 32x32x3)\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation function\n",
    "        # x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))  # Apply ReLU activation function\n",
    "        # x = self.dropout2(x)\n",
    "        x = self.fc3(x)  # Output layer (no activation)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TwoFCLayers().to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "\n",
    "# Lists to store loss and accuracy per epoch\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs, device):\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        train_loss = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        train_losses.append(train_loss / len(train_loader))  # Average train loss\n",
    "\n",
    "        # Validation/Test phase\n",
    "        model.eval()\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Track accuracy\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_accuracy = correct_test / total_test * 100\n",
    "        test_losses.append(test_loss / len(test_loader))  # Average test loss\n",
    "\n",
    "        # Store values for plotting\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}% | Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}% | Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    print(f\"Final Train Accuracy: {train_accuracy:.2f}% | Final Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    return model, train_losses, test_losses, train_accuracies, test_accuracies\n",
    "\n",
    "# Train the model\n",
    "model, train_losses, test_losses, train_accuracies, test_accuracies = train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs, device)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = \"saved_models/gtsrb_model_fcnn_obscured_train.pth\"\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2cea2-9a9a-4f66-830f-447d3840feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot accuracy and loss curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs+1), test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Training and Testing Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Testing Loss')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f74fe7-ae26-479f-bc83-2c69706049fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect true and predicted labels for the test dataset\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculations\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Append labels\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=list(range(num_classes)))\n",
    "\n",
    "# Set a custom figure size\n",
    "fig, ax = plt.subplots(figsize=(20, 20))  # Adjust the size as needed\n",
    "\n",
    "# Display the confusion matrix with explicit axes\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(num_classes)))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax, xticks_rotation='vertical')  # Pass the custom axes\n",
    "\n",
    "# Add title and show the plot\n",
    "plt.title(\"Confusion Matrix - FCNN Model (Obscured Image Data)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
